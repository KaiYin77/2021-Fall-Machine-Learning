{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw1_0710851.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "interpreter": {
      "hash": "b445ccfa557170e9a1397e58540c0ba15a3370c0d87db55f340afe85843e37a4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVEheEreJqAq"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from numpy.linalg import inv\n",
        "\n",
        "# Loading Data_Frame\n",
        "data_x_df = pd.read_csv('data_X.csv')\n",
        "data_t_df = pd.read_csv('data_T.csv')\n",
        "data_df = pd.merge(data_x_df, data_t_df, left_index=True, right_index=True)\n",
        "\n",
        "sizeData = data_df.shape[0]\n",
        "sizeFeature = data_df.shape[1]\n",
        "\n",
        "# Create Dataset\n",
        "rawData = np.array(data_df)\n",
        "\n",
        "# Random Shuffle for Raw Data\n",
        "np.random.shuffle(rawData)\n",
        "\n",
        "# Split Dataset into Train & Valid set\n",
        "trainData = rawData[:int(sizeData*90/100)]\n",
        "valData = rawData[int((-sizeData)*10/100):]\n",
        "\n",
        "sizeTrain = trainData.shape[0]\n",
        "sizeVal = valData.shape[0]"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjy-1dHeTtN9"
      },
      "source": [
        "\"\"\"\n",
        "Function:\n",
        "- Create Phi(x) for M=1 & M=2\n",
        "\n",
        "Parameters:\n",
        "- train: trainData[:, :-1]\n",
        "\"\"\"\n",
        "def createPhi(train):\n",
        "    len = train.shape[1]\n",
        "    \n",
        "    # M >= 1\n",
        "    phiOne = np.insert(train, 0, values=np.ones(train.shape[0]), axis=1)\n",
        "    \n",
        "    # M >= 2\n",
        "    phiTwo = phiOne\n",
        "    diff = 0\n",
        "    offset = len + 1;\n",
        "    for i in range(len):\n",
        "        for j in range(len):\n",
        "            if i <= j:\n",
        "                offset += 1\n",
        "                phiTwo = np.insert(phiTwo, \n",
        "                                  i*len + j + len + 1 - diff,\n",
        "                                  values = train[:, i]*train[:, j],\n",
        "                                  axis = 1)\n",
        "            else:\n",
        "                diff += 1\n",
        "    # M >= 3\n",
        "    diff = 0\n",
        "    phiThree = phiTwo\n",
        "    for i in range(len):\n",
        "        for j in range(len):\n",
        "            for k in range(len):\n",
        "                if i <= j and j <= k:\n",
        "                    phiThree = np.insert(phiThree,\n",
        "                                        i*len*len + j*len + k + offset - diff,\n",
        "                                        values = train[:, i]*train[:, j]*train[:, k],\n",
        "                                        axis = 1)\n",
        "                else:\n",
        "                    diff += 1\n",
        "\n",
        "    return phiOne, phiTwo, phiThree"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJmNXemiyjGv"
      },
      "source": [
        "\"\"\"\n",
        "Function:\n",
        "- Create y(x,w) as Prediction function\n",
        "\n",
        "Parameters:\n",
        "- inputX : trainData[:, :-1]\n",
        "- inputT : trainData[:, -1]\n",
        "\n",
        "Return:\n",
        "- Root Mean Square Value\n",
        "\"\"\"\n",
        "def prediction(inputX, inputT, M, weight):\n",
        "    len = inputX.shape[1] #8\n",
        "    y = np.zeros(inputX.shape[0])\n",
        "    y += weight[0]\n",
        "    \n",
        "    # M >= 1 \n",
        "    for i in range(len):\n",
        "        m1 = np.multiply(inputX[:, i], weight[i+1])\n",
        "        y += m1\n",
        "    \n",
        "    # M >= 2 with interaction terms\n",
        "    offset = len + 1;\n",
        "    if M >= 2:\n",
        "        diff = 0\n",
        "        for i in range(len):\n",
        "            for j in range(len):\n",
        "                if i <= j:\n",
        "                    offset += 1\n",
        "                    m2 = np.multiply(inputX[:, i], inputX[:, j])\n",
        "                    y += np.multiply(m2, weight[i*len + j + len + 1 - diff])\n",
        "                else:\n",
        "                    diff += 1\n",
        "    \n",
        "    # M >= 3 with interaction terms (for (2-b))\n",
        "    if M >= 3:\n",
        "        diff = 0\n",
        "        for i in range(len):\n",
        "          for j in range(len):\n",
        "              for k in range(len):\n",
        "                  if i <= j and j <= k:\n",
        "                      m3 = np.multiply(np.multiply(inputX[:, i], inputX[:, j]), inputX[:, k])\n",
        "                      y += np.multiply(m3, weight[i*len*len + j*len + k + offset - diff])                    \n",
        "                  else:\n",
        "                      diff += 1\n",
        "    \n",
        "    return np.sqrt(np.mean((y - inputT)**2)) "
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGezVbg_SLaC"
      },
      "source": [
        "# Feature Selection - (a)\n",
        "phiOne, phiTwo, _ = createPhi(trainData[..., :-1])\n",
        "\n",
        "# perform Least Square solution\n",
        "\"\"\"\n",
        "(X.T*X)-1 * X.T * Y\n",
        "\"\"\"\n",
        "weightM1 = np.dot(np.dot(\n",
        "                      np.linalg.pinv(np.dot(phiOne.T, phiOne)),\n",
        "                      phiOne.T\n",
        "                  ),\n",
        "                  trainData[:, -1]) # Target\n",
        "weightM2 = np.dot(np.dot(\n",
        "                      np.linalg.pinv(np.dot(phiTwo.T, phiTwo)),\n",
        "                      phiTwo.T\n",
        "                  ),\n",
        "                  trainData[:, -1]) # Target\n",
        "\n",
        "train_MLE_RMS = [prediction(trainData[..., :-1], trainData[..., -1], 1, weightM1), \n",
        "            prediction(trainData[..., :-1], trainData[..., -1], 2, weightM2)]\n",
        "val_MLE_RMS = [prediction(valData[..., :-1], valData[..., -1], 1, weightM1), \n",
        "            prediction(valData[..., :-1], valData[..., -1], 2, weightM2)]\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8CG79YmU3p9",
        "outputId": "8d9e78dc-5d4a-49ab-c492-0db48ebdfbb7"
      },
      "source": [
        "print(\"===Feature Selection - (a)===\\n\")\n",
        "print(\"Weight : \\n\")\n",
        "print(\"M = 1 : \\n\", weightM1)\n",
        "print(\"M = 2 : \\n\", weightM2, '\\n')\n",
        "\n",
        "print(\"Trainning set's RMS result:\")\n",
        "print(\"M = 1  \", train_MLE_RMS[0])\n",
        "print(\"M = 2  \", train_MLE_RMS[1], '\\n')\n",
        "\n",
        "print(\"Valid set's RMS result:\")\n",
        "print(\"M = 1  \", val_MLE_RMS[0])\n",
        "print(\"M = 2  \", val_MLE_RMS[1], '\\n')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===Feature Selection - (a)===\n",
            "\n",
            "Weight : \n",
            "\n",
            "M = 1 : \n",
            " [-3.60904109e+06 -4.29905734e+04 -4.27257971e+04  1.15824952e+03\n",
            " -8.12307821e+00  1.16523115e+02 -3.73516536e+01  4.20719286e+01\n",
            "  4.02625928e+04]\n",
            "M = 2 : \n",
            " [ 7.07313286e-01  1.33908244e+02 -4.36977990e+01 -3.13917693e+01\n",
            " -6.25494223e+02 -2.47491682e+02 -1.75578351e+02 -1.41007836e+02\n",
            "  2.43588580e+01  3.26493288e+01  2.04228872e+02 -2.75549531e+01\n",
            " -6.23998414e+00 -7.86675495e+00 -2.47546488e-01 -5.39105708e+00\n",
            " -9.08563744e+02  3.23911790e+02 -1.29283457e+02 -4.84691360e+00\n",
            " -7.54384210e+00  4.82273640e+00 -2.09195367e+01 -1.39097373e+03\n",
            "  2.69861853e+01 -5.50037072e-01  2.49793535e+00 -1.63749410e+00\n",
            "  5.11040726e+00  2.63331348e+02 -1.97784014e-03  4.71217723e-02\n",
            " -3.27899560e-03 -9.13028129e-03  8.59841851e+00 -2.15317243e-01\n",
            "  1.33384838e-02  9.74260707e-02 -5.09446259e+01  3.59065058e-03\n",
            " -2.40551442e-02 -8.06212160e+00  2.05003519e-02  3.24610701e+01\n",
            " -2.33700717e+03] \n",
            "\n",
            "Trainning set's RMS result:\n",
            "M = 1   69506.21518118356\n",
            "M = 2   66902.66248693895 \n",
            "\n",
            "Valid set's RMS result:\n",
            "M = 1   70047.83700973312\n",
            "M = 2   66777.47111162756 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqGKu9zINwOZ"
      },
      "source": [
        "# Feature Selection - (b)\n",
        "\n",
        "deleteOneOfFeature = [np.delete(trainData, i, 1) for i in range(trainData.shape[1]-1)]\n",
        "\n",
        "phiOneArray = []\n",
        "for i in range(trainData.shape[1]-1):\n",
        "    _phiOne, _ , _= createPhi(deleteOneOfFeature[i][...,:-1])\n",
        "    phiOneArray.append(_phiOne)\n",
        "\n",
        "weightMLE1Array = []\n",
        "for i in range(trainData.shape[1]-1):\n",
        "    _weightM1 = np.dot(np.dot(\n",
        "                      np.linalg.pinv(np.dot(phiOneArray[i].T, phiOneArray[i])),\n",
        "                      phiOneArray[i].T\n",
        "                  ),\n",
        "                  deleteOneOfFeature[i][..., -1]) # Target\n",
        "    weightMLE1Array.append(_weightM1)          \n",
        "      \n",
        "train_MLE_RMS_Array = []\n",
        "for i in range(trainData.shape[1]-1):\n",
        "    _trainRMS = prediction(deleteOneOfFeature[i][..., :-1], deleteOneOfFeature[i][..., -1], 1, weightMLE1Array[i])\n",
        "    train_MLE_RMS_Array.append(_trainRMS)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNT59kVVaYh5",
        "outputId": "d7e93a5b-b221-4581-eb6e-615a3d61dff0"
      },
      "source": [
        "print(\"===Feature Selection - (b)===\\n\")\n",
        "\n",
        "for i in range(len(train_MLE_RMS_Array)):\n",
        "    print(\"Delete No.\", i+1, \"Feature => RMS would be : \",train_MLE_RMS_Array[i])\n",
        "\n",
        "print(\"\\n\\nWe can find that the final RMS is the most,\")\n",
        "print(\"which means without the median_income, the final predict would be the most unreliable.\\n\")\n",
        "print(\"[Median_income] is the most contributive feature!!\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===Feature Selection - (b)===\n",
            "\n",
            "Delete No. 1 Feature => RMS would be :  75378.9699778046\n",
            "Delete No. 2 Feature => RMS would be :  75981.25850956484\n",
            "Delete No. 3 Feature => RMS would be :  70710.1716584494\n",
            "Delete No. 4 Feature => RMS would be :  69685.33428453187\n",
            "Delete No. 5 Feature => RMS would be :  69983.26355475682\n",
            "Delete No. 6 Feature => RMS would be :  71552.24533191256\n",
            "Delete No. 7 Feature => RMS would be :  69558.67572081064\n",
            "Delete No. 8 Feature => RMS would be :  90840.63228032186\n",
            "\n",
            "\n",
            "We can find that the final RMS is the most,\n",
            "which means without the median_income, the final predict would be the most unreliable.\n",
            "\n",
            "[Median_income] is the most contributive feature!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zK4s02Y4kur",
        "outputId": "f4641258-1626-4d32-dc2b-0e79c9ee9878"
      },
      "source": [
        "# Maximum likelihood approach - (a)\n",
        "print(\"===Maximum likelihood approach - (a)===\\n\")\n",
        "print('Choose [Polynomial] as the basis function!!')\n",
        "print('1. Polynomial models have moderate flexibility of shapes.')\n",
        "print('2. The higher order of Polynomial models can present the interactions between variables.')\n",
        "print('3. Polynomial models have well known and understood properties.')\n",
        "print('4. Besides, Polynomial model is easy to implement.')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===Maximum likelihood approach - (a)===\n",
            "\n",
            "Choose [Polynomial] as the basis function!!\n",
            "1. Polynomial models have moderate flexibility of shapes.\n",
            "2. The higher order of Polynomial models can present the interactions between variables.\n",
            "3. Polynomial models have well known and understood properties.\n",
            "4. Besides, Polynomial model is easy to implement.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQ45jyYSwqq1"
      },
      "source": [
        "\"\"\"\n",
        "Function:\n",
        "- Gauss-Jordan elimanation\n",
        "\n",
        "Parameters:\n",
        "- matrix\n",
        "\n",
        "Return:\n",
        "- inverse matrix\n",
        "\"\"\"\n",
        "\n",
        "def Gauss_Jordan(M):\n",
        "    # Applying Gauss Jordan Elimination\n",
        "    I = np.eye(M.shape[0])\n",
        "    inv = np.linalg.solve(M, I)\n",
        "    return inv"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aHVUxMtbiIt"
      },
      "source": [
        "# Maximum likelihood approach - (b)\n",
        "\n",
        "_, _, phiThree = createPhi(trainData[..., :-1])\n",
        "\n",
        "# perform Least Square solution\n",
        "# \"\"\"\n",
        "# W = (X.T*X)^-1 * X.T * Y\n",
        "# \"\"\"\n",
        "\n",
        "_inv = Gauss_Jordan(np.dot(phiThree.T, phiThree))\n",
        "weightM3 = np.dot(np.dot(\n",
        "                      _inv,\n",
        "                      phiThree.T),\n",
        "                  trainData[:, -1]) # Target\n",
        "\n",
        "_train_MLE_RMS = prediction(trainData[..., :-1], trainData[..., -1], 3, weightM3)\n",
        "_val_MLE_RMS = prediction(valData[..., :-1], valData[..., -1], 3, weightM3)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpZrSsZYfxWs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dee5e9b-1a47-4357-f38c-59a084e3a4ca"
      },
      "source": [
        "# Maximum likelihood approach - (b)\n",
        "print(\"===Maximum likelihood approach - (b)===\\n\")\n",
        "\n",
        "print('As polynomial model become higher degree, the curve may oscillate between exact-fit values.')\n",
        "print('However, Setting M = 3 is also suitable for this case. (See below)')\n",
        "print('For the higher order of M, we may see training loss is low but validation loss is high!\\n')\n",
        "\n",
        "print(\"Trainning set's RMS result:\")\n",
        "print(\"M = 1  \", train_MLE_RMS[0])\n",
        "print(\"M = 2  \", train_MLE_RMS[1])\n",
        "print(\"M = 3  \", _train_MLE_RMS, '\\n')\n",
        "\n",
        "print(\"Valid set's RMS result:\")\n",
        "print(\"M = 1  \", val_MLE_RMS[0])\n",
        "print(\"M = 2  \", val_MLE_RMS[1])\n",
        "print(\"M = 3  \", _val_MLE_RMS, '\\n')\n",
        "\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===Maximum likelihood approach - (b)===\n",
            "\n",
            "As polynomial model become higher degree, the curve may oscillate between exact-fit values.\n",
            "However, Setting M = 3 is also suitable for this case. (See below)\n",
            "For the higher order of M, we may see training loss is low but validation loss is high!\n",
            "\n",
            "Trainning set's RMS result:\n",
            "M = 1   69506.21518118356\n",
            "M = 2   66902.66248693895\n",
            "M = 3   58511.594878433185 \n",
            "\n",
            "Valid set's RMS result:\n",
            "M = 1   70047.83700973312\n",
            "M = 2   66777.47111162756\n",
            "M = 3   63580.02301346249 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tSy89qr0xmm"
      },
      "source": [
        "# Maximum likelihood approach - (c)\n",
        "\n",
        "# Apply N-fold cross-validation\n",
        "N_Fold = 100\n",
        "sizeFold = int(trainData.shape[0]/N_Fold)\n",
        "\n",
        "for n in range(N_Fold):\n",
        "    _val = trainData[sizeFold*n:sizeFold*(n+1), :]\n",
        "    _train = np.concatenate((trainData[0:sizeFold*n, :], trainData[sizeFold*(n+1):, :]))\n",
        "\n",
        "    _phiOne, _phiTwo, _ = createPhi(_train[..., :-1])\n",
        "\n",
        "    _wM1 = np.dot(np.dot(\n",
        "                      np.linalg.pinv(np.dot(_phiOne.T, _phiOne)),\n",
        "                     _phiOne.T\n",
        "                  ),\n",
        "                  _train[:, -1]) # Target\n",
        "    _wM2 = np.dot(np.dot(\n",
        "                      np.linalg.pinv(np.dot(_phiTwo.T, _phiTwo)),\n",
        "                      _phiTwo.T\n",
        "                  ),\n",
        "                  _train[:, -1]) # Target\n",
        "    if n==0:\n",
        "        _weightM1 = _wM1\n",
        "        _weightM2 = _wM2\n",
        "    else:\n",
        "        _weightM1 += _wM1\n",
        "        _weightM2 += _wM2\n",
        "    \n",
        "_weightM1 = _weightM1/N_Fold\n",
        "_weightM2 = _weightM2/N_Fold\n",
        "\n",
        "train_MLE_RMS_N_Fold = [prediction(trainData[..., :-1], trainData[..., -1], 1, _weightM1), \n",
        "            prediction(trainData[..., :-1], trainData[..., -1], 2, _weightM2)]\n",
        "val_MLE_RMS_N_Fold = [prediction(valData[..., :-1], valData[..., -1], 1, _weightM1), \n",
        "            prediction(valData[..., :-1], valData[..., -1], 2, _weightM2)]"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cohmhm_n1__A",
        "outputId": "3681ad15-bf51-48e5-e782-f247470d9bab"
      },
      "source": [
        "print(\"===Maximum likelihood approach - (c)===\\n\")\n",
        "print('Selecting two different order to compare the behavior of model when performing N-Fold cross validation,')\n",
        "print('We can found when test validation set in M = 2, the RMS tilts up,')\n",
        "print('We can conclude that M = 2 may be too much complex for this scenario,')\n",
        "print('Since its RMS perform like overfitting,')\n",
        "\n",
        "print(\"Trainning set's RMS result with N-fold cross-validation:\")\n",
        "print(\"M = 1  \", train_MLE_RMS_N_Fold[0])\n",
        "print(\"M = 2  \", train_MLE_RMS_N_Fold[1], '\\n')\n",
        "\n",
        "print(\"Valid set's RMS result with N-fold cross-validation:\")\n",
        "print(\"M = 1  \", val_MLE_RMS_N_Fold[0])\n",
        "print(\"M = 2  \", val_MLE_RMS_N_Fold[1], '\\n')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===Maximum likelihood approach - (c)===\n",
            "\n",
            "Selecting two different order to compare the behavior of model when performing N-Fold cross validation,\n",
            "We can found when test validation set in M = 2, the RMS tilts up,\n",
            "We can conclude that M = 2 may be too much complex for this scenario,\n",
            "Since its RMS perform like overfitting,\n",
            "Trainning set's RMS result with N-fold cross-validation:\n",
            "M = 1   69506.2153257171\n",
            "M = 2   66902.54775727756 \n",
            "\n",
            "Valid set's RMS result with N-fold cross-validation:\n",
            "M = 1   70047.5561857142\n",
            "M = 2   66775.36479322216 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_9cfKpu-8AK",
        "outputId": "bf5ad713-f256-48e8-eb62-3682c9e46655"
      },
      "source": [
        "# Maximum A Posterior - (a)\n",
        "print(\"===Maximum a  Posterior approach - (a)===\\n\")\n",
        "print('The key difference between MLP & MAP approach:')\n",
        "print('If we have prior information, then MAP approach is the good way.')\n",
        "print('Since MLE produces model params. most likely to generate the observed data.')\n",
        "print('While if no such prior probalilty, then MLE is a reasonable approach.')\n",
        "print('Since MAP is the model params that is most likely given the observed data.')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===Maximum a  Posterior approach - (a)===\n",
            "\n",
            "The key difference between MLP & MAP approach:\n",
            "If we have prior information, then MAP approach is the good way.\n",
            "Since MLE produces model params. most likely to generate the observed data.\n",
            "While if no such prior probalilty, then MLE is a reasonable approach.\n",
            "Since MAP is the model params that is most likely given the observed data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iTO3Bqx-Zym"
      },
      "source": [
        "# Maximum A Posterior - (b)\n",
        "\n",
        "# Apply a regularizer to (2), the approach will be MAP estimation.\n",
        "\n",
        "N_Fold = 100\n",
        "sizeFold = int(trainData.shape[0]/N_Fold)\n",
        "paramLambda = 0.1\n",
        "\n",
        "for n in range(N_Fold):\n",
        "    _val = trainData[sizeFold*n:sizeFold*(n+1), :]\n",
        "    _train = np.concatenate((trainData[0:sizeFold*n, :], trainData[sizeFold*(n+1):, :]))\n",
        "\n",
        "    # perform Least Square solution\n",
        "    # \"\"\"\n",
        "    # W = (lambdaI+ X.T*X)^-1 * X.T * Y\n",
        "    # \"\"\" \n",
        "    _phiOne, _phiTwo, _ = createPhi(_train[..., :-1])\n",
        "\n",
        "    _wMAP1 = np.dot(np.dot(\n",
        "                      np.linalg.pinv((paramLambda* np.eye(_phiOne.shape[1]) + np.dot(_phiOne.T, _phiOne))),\n",
        "                     _phiOne.T\n",
        "                  ),\n",
        "                  _train[:, -1]) # Target\n",
        "    _wMAP2 = np.dot(np.dot(\n",
        "                      np.linalg.pinv((paramLambda* np.eye(_phiTwo.shape[1]) + np.dot(_phiTwo.T, _phiTwo))),\n",
        "                      _phiTwo.T\n",
        "                  ),\n",
        "                  _train[:, -1]) # Target\n",
        "    if n==0:\n",
        "        _weightMAP1 = _wMAP1\n",
        "        _weightMAP2 = _wMAP2\n",
        "    else:\n",
        "        _weightMAP1 += _wMAP1\n",
        "        _weightMAP2 += _wMAP2\n",
        "    \n",
        "_weightMAP1 = _weightMAP1/N_Fold\n",
        "_weightMAP2 = _weightMAP2/N_Fold\n",
        "\n",
        "train_MAP_RMS_N_Fold = [prediction(trainData[..., :-1], trainData[..., -1], 1, _weightMAP1), \n",
        "            prediction(trainData[..., :-1], trainData[..., -1], 2, _weightMAP2)]\n",
        "val_MAP_RMS_N_Fold = [prediction(valData[..., :-1], valData[..., -1], 1, _weightMAP1), \n",
        "            prediction(valData[..., :-1], valData[..., -1], 2, _weightMAP2)]"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DG-E07cZGwjL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7155be7-0d6e-479d-cfd8-d3e07d98fa4c"
      },
      "source": [
        "print(\"===Maximum a  Posterior approach - (b)===\\n\")\n",
        "\n",
        "print(\"Trainning set's RMS result with N-fold cross-validation:\")\n",
        "print(\"M = 1  \", train_MAP_RMS_N_Fold[0])\n",
        "print(\"M = 2  \", train_MAP_RMS_N_Fold[1], '\\n')\n",
        "\n",
        "print(\"Valid set's RMS result with N-fold cross-validation:\")\n",
        "print(\"M = 1  \", val_MAP_RMS_N_Fold[0])\n",
        "print(\"M = 2  \", val_MAP_RMS_N_Fold[1], '\\n')"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===Maximum a  Posterior approach - (b)===\n",
            "\n",
            "Trainning set's RMS result with N-fold cross-validation:\n",
            "M = 1   69545.83395221547\n",
            "M = 2   66902.50002653379 \n",
            "\n",
            "Valid set's RMS result with N-fold cross-validation:\n",
            "M = 1   70024.6751450012\n",
            "M = 2   66775.29333980981 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6kagc3XCXne",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3fdb261-7c1f-4c1e-a190-38f154572b51"
      },
      "source": [
        "print(\"===Maximum a  Posterior approach - (c)===\\n\")\n",
        "print('The approach difference is presented above.')\n",
        "print(\"But compare with MLE result, show quite similar.\")\n",
        "print(\"Something I have to say is that MAP is still a bit worse than MLE in this case.\")\n",
        "print(\"If data is big enough, MLE and MAP will converge to same value\")\n",
        "print(\"When data is less, the hyper parameter we choose may influence results a lot.\")\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===Maximum a  Posterior approach - (c)===\n",
            "\n",
            "The approach difference is presented above.\n",
            "But compare with MLE result, show quite similar.\n",
            "Something I have to say is that MAP is still a bit worse than MLE in this case.\n",
            "If data is big enough, MLE and MAP will converge to same value\n",
            "When data is less, the hyper parameter we choose may influencet results a lot.\n"
          ]
        }
      ]
    }
  ]
}